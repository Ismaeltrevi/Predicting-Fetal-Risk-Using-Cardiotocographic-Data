{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Process With Experimental Feature Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this notebook we use our experimental database to identify key features and tune the hyperparameters of several high preforming models. For model selection, we where looking for models where we could best improve the precision(reduce false positives) while not drastically reducing recall (false negatives).  To evaluate the models we used sklearn metrics and also viewed the confusion matrix to see how the models predictions on the test set preformed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:31.692080Z",
     "start_time": "2021-02-22T00:36:28.186415Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import Packages\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sklearn Packages\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, precision_score, confusion_matrix, accuracy_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import set_config\n",
    "set_config(print_changed_only=False)\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils.testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from xgboost import plot_importance\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "pd.set_option('display.max_columns', 300)\n",
    "% matplotlib inline\n",
    "\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:31.810897Z",
     "start_time": "2021-02-22T00:36:31.697780Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline value</th>\n",
       "      <th>accelerations</th>\n",
       "      <th>fetal_movement</th>\n",
       "      <th>uterine_contractions</th>\n",
       "      <th>light_decelerations</th>\n",
       "      <th>prolongued_decelerations</th>\n",
       "      <th>abnormal_short_term_variability</th>\n",
       "      <th>mean_value_of_short_term_variability</th>\n",
       "      <th>percentage_of_time_with_abnormal_long_term_variability</th>\n",
       "      <th>mean_value_of_long_term_variability</th>\n",
       "      <th>histogram_width</th>\n",
       "      <th>histogram_min</th>\n",
       "      <th>histogram_max</th>\n",
       "      <th>histogram_number_of_peaks</th>\n",
       "      <th>histogram_mode</th>\n",
       "      <th>histogram_mean</th>\n",
       "      <th>histogram_median</th>\n",
       "      <th>histogram_variance</th>\n",
       "      <th>fetal_health</th>\n",
       "      <th>uterine_cont_per_min</th>\n",
       "      <th>total_change</th>\n",
       "      <th>sqrt_total_change</th>\n",
       "      <th>hist_zeros_1.0</th>\n",
       "      <th>hist_zeros_2.0</th>\n",
       "      <th>hist_zeros_3.0</th>\n",
       "      <th>hist_zeros_4.0</th>\n",
       "      <th>hist_zeros_5.0</th>\n",
       "      <th>hist_zeros_7.0</th>\n",
       "      <th>hist_zeros_8.0</th>\n",
       "      <th>hist_zeros_10.0</th>\n",
       "      <th>hist_tendancy_0.0</th>\n",
       "      <th>hist_tendancy_1.0</th>\n",
       "      <th>sev_decel_0.001</th>\n",
       "      <th>quant_acc_1</th>\n",
       "      <th>quant_light_dec_1</th>\n",
       "      <th>quant_hist_mean_1</th>\n",
       "      <th>quant_hist_mean_2</th>\n",
       "      <th>quant_hist_mean_3</th>\n",
       "      <th>quant_hist_mean_4</th>\n",
       "      <th>quant_hist_mean_5</th>\n",
       "      <th>quant_hist_mean_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>64.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>130.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.980</td>\n",
       "      <td>0.122474</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>130.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.862</td>\n",
       "      <td>0.118322</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>134.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.876</td>\n",
       "      <td>0.118322</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132.0</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.9</td>\n",
       "      <td>117.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.980</td>\n",
       "      <td>0.122474</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   baseline value  accelerations  fetal_movement  uterine_contractions  \\\n",
       "0           120.0          0.000             0.0                 0.000   \n",
       "1           132.0          0.006             0.0                 0.006   \n",
       "2           133.0          0.003             0.0                 0.008   \n",
       "3           134.0          0.003             0.0                 0.008   \n",
       "4           132.0          0.007             0.0                 0.008   \n",
       "\n",
       "   light_decelerations  prolongued_decelerations  \\\n",
       "0                0.000                       0.0   \n",
       "1                0.003                       0.0   \n",
       "2                0.003                       0.0   \n",
       "3                0.003                       0.0   \n",
       "4                0.000                       0.0   \n",
       "\n",
       "   abnormal_short_term_variability  mean_value_of_short_term_variability  \\\n",
       "0                             73.0                                   0.5   \n",
       "1                             17.0                                   2.1   \n",
       "2                             16.0                                   2.1   \n",
       "3                             16.0                                   2.4   \n",
       "4                             16.0                                   2.4   \n",
       "\n",
       "   percentage_of_time_with_abnormal_long_term_variability  \\\n",
       "0                                               43.0        \n",
       "1                                                0.0        \n",
       "2                                                0.0        \n",
       "3                                                0.0        \n",
       "4                                                0.0        \n",
       "\n",
       "   mean_value_of_long_term_variability  histogram_width  histogram_min  \\\n",
       "0                                  2.4             64.0           62.0   \n",
       "1                                 10.4            130.0           68.0   \n",
       "2                                 13.4            130.0           68.0   \n",
       "3                                 23.0            117.0           53.0   \n",
       "4                                 19.9            117.0           53.0   \n",
       "\n",
       "   histogram_max  histogram_number_of_peaks  histogram_mode  histogram_mean  \\\n",
       "0          126.0                        2.0           120.0           137.0   \n",
       "1          198.0                        6.0           141.0           136.0   \n",
       "2          198.0                        5.0           141.0           135.0   \n",
       "3          170.0                       11.0           137.0           134.0   \n",
       "4          170.0                        9.0           137.0           136.0   \n",
       "\n",
       "   histogram_median  histogram_variance  fetal_health  uterine_cont_per_min  \\\n",
       "0             121.0                73.0           2.0                  0.00   \n",
       "1             140.0                12.0           1.0                  0.36   \n",
       "2             138.0                13.0           1.0                  0.48   \n",
       "3             137.0                13.0           1.0                  0.48   \n",
       "4             138.0                11.0           1.0                  0.48   \n",
       "\n",
       "   total_change  sqrt_total_change  hist_zeros_1.0  hist_zeros_2.0  \\\n",
       "0         0.000           0.000000               0               0   \n",
       "1         1.980           0.122474               1               0   \n",
       "2         1.862           0.118322               1               0   \n",
       "3         1.876           0.118322               0               0   \n",
       "4         1.980           0.122474               0               0   \n",
       "\n",
       "   hist_zeros_3.0  hist_zeros_4.0  hist_zeros_5.0  hist_zeros_7.0  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   hist_zeros_8.0  hist_zeros_10.0  hist_tendancy_0.0  hist_tendancy_1.0  \\\n",
       "0               0                0                  0                  1   \n",
       "1               0                0                  1                  0   \n",
       "2               0                0                  1                  0   \n",
       "3               0                0                  0                  1   \n",
       "4               0                0                  0                  1   \n",
       "\n",
       "   sev_decel_0.001  quant_acc_1  quant_light_dec_1  quant_hist_mean_1  \\\n",
       "0                0            0                  0                  0   \n",
       "1                0            0                  0                  0   \n",
       "2                0            0                  0                  0   \n",
       "3                0            0                  0                  0   \n",
       "4                0            1                  0                  0   \n",
       "\n",
       "   quant_hist_mean_2  quant_hist_mean_3  quant_hist_mean_4  quant_hist_mean_5  \\\n",
       "0                  0                  1                  0                  0   \n",
       "1                  0                  1                  0                  0   \n",
       "2                  0                  1                  0                  0   \n",
       "3                  0                  1                  0                  0   \n",
       "4                  0                  1                  0                  0   \n",
       "\n",
       "   quant_hist_mean_6  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in dataframe\n",
    "exp_df = pd.read_csv('experiment_features.csv',index_col=0)\n",
    "exp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:31.822584Z",
     "start_time": "2021-02-22T00:36:31.814017Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluation(y_true, y_pred):\n",
    "    \n",
    "# Print Accuracy, Recall, F1 Score, and Precision metrics.\n",
    "    print('Evaluation Metrics:')\n",
    "    print('Accuracy: ' + str(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('Recall: ' + str(metrics.recall_score(y_test, y_pred)))\n",
    "    print('F1 Score: ' + str(metrics.f1_score(y_test, y_pred)))\n",
    "    print('Precision: ' + str(metrics.precision_score(y_test, y_pred)))\n",
    "    \n",
    "# Print Confusion Matrix\n",
    "    print('\\nConfusion Matrix:')\n",
    "    print(' TN,  FP, FN, TP')\n",
    "    print(confusion_matrix(y_true, y_pred).ravel())\n",
    "    \n",
    "# Function Prints best parameters for GridSearchCV\n",
    "def print_results(results):\n",
    "    print('Best Parameters: {}\\n'.format(results.best_params_))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:31.835602Z",
     "start_time": "2021-02-22T00:36:31.825633Z"
    }
   },
   "outputs": [],
   "source": [
    "#train test split of data\n",
    "X = exp_df.drop('fetal_health', axis =1)\n",
    "y = exp_df.fetal_health\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:31.848917Z",
     "start_time": "2021-02-22T00:36:31.837698Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#standared scaler for predicting features\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To handle class imbalance we oversampled the minority class using SMOTE(Synthetic Minority Oversampling Technique), this balanced the minority class by sampling the nearest neighboors and adding points between the neighbors.  We used both a SMOTE sampled database and unbalanced database to compare the effect of the metrics for each experimental baseline model.  The Smote Database preformed better on every baseline model, we chose to use the SMOTE database for our final models.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:31.882610Z",
     "start_time": "2021-02-22T00:36:31.851171Z"
    }
   },
   "outputs": [],
   "source": [
    "#Used smote to oversample minority class\n",
    "sm = SMOTE(random_state=25)\n",
    "smX_train, smy_train = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here we ran a basline model of knn on the experimental database and compared the metrics results to the database treated with smote.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:31.902204Z",
     "start_time": "2021-02-22T00:36:31.884744Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#baseline KNN with class imbalance\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:31.951598Z",
     "start_time": "2021-02-22T00:36:31.908919Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:31.974262Z",
     "start_time": "2021-02-22T00:36:31.955909Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.9172932330827067\n",
      "Recall: 0.9682151589242054\n",
      "F1 Score: 0.9473684210526316\n",
      "Precision: 0.927400468384075\n",
      "\n",
      "Confusion Matrix:\n",
      " TN,  FP, FN, TP\n",
      "[396  13  31  92]\n"
     ]
    }
   ],
   "source": [
    "#prediction metrics and confusion matrix of base KNN with class imbalance\n",
    "evaluation(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:32.021433Z",
     "start_time": "2021-02-22T00:36:31.976824Z"
    }
   },
   "outputs": [],
   "source": [
    "#Base KNN model with Smote oversampled class\n",
    "smknn = KNeighborsClassifier(n_neighbors=1)\n",
    "smknn.fit(smX_train,smy_train)\n",
    "y_pred = smknn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:32.040096Z",
     "start_time": "2021-02-22T00:36:32.023961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.9172932330827067\n",
      "Recall: 0.9584352078239609\n",
      "F1 Score: 0.9468599033816426\n",
      "Precision: 0.9355608591885441\n",
      "\n",
      "Confusion Matrix:\n",
      " TN,  FP, FN, TP\n",
      "[392  17  27  96]\n"
     ]
    }
   ],
   "source": [
    "#Prediction metrics and confusion matrix of smote base KNN\n",
    "evaluation(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Basline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here are two Logistic regression Models comparing the effect of SMOTE on the metric scores.  SMOTE greatly improved the precision of the model, however Recall was greatly reduced.  While one of the aims for our project was to improve precision as best we can, too many false negatives are not ideal for the overal fetal mortality rate.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:32.785390Z",
     "start_time": "2021-02-22T00:36:32.043264Z"
    }
   },
   "outputs": [],
   "source": [
    "#Fit Train set with Logistic Regression model\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:32.811880Z",
     "start_time": "2021-02-22T00:36:32.788564Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.8778195488721805\n",
      "Recall: 0.9388753056234719\n",
      "F1 Score: 0.921968787515006\n",
      "Precision: 0.9056603773584906\n",
      "\n",
      "Confusion Matrix:\n",
      " TN,  FP, FN, TP\n",
      "[384  25  40  83]\n"
     ]
    }
   ],
   "source": [
    "#Regression model evaluation metrics and confusion matrix\n",
    "evaluation(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:32.905961Z",
     "start_time": "2021-02-22T00:36:32.814560Z"
    }
   },
   "outputs": [],
   "source": [
    "smlr = LogisticRegression(solver='liblinear')\n",
    "smlr.fit(smX_train,smy_train)\n",
    "y_predsm = smlr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:32.932697Z",
     "start_time": "2021-02-22T00:36:32.909011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.8853383458646616\n",
      "Recall: 0.8801955990220048\n",
      "F1 Score: 0.9218950064020486\n",
      "Precision: 0.967741935483871\n",
      "\n",
      "Confusion Matrix:\n",
      " TN,  FP, FN, TP\n",
      "[360  49  12 111]\n"
     ]
    }
   ],
   "source": [
    "evaluation(y_test, y_predsm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Below is a table of feature coefficients for the Logistic Regression.  The greatest feature Coefficients are sqrt_total_change, quant_acc_1, quant_hist_mean(1 2 and 3) and tendancy_1.  All of these features are ones that we engineered.  Looking at what these features represent, for this model, the change in the rate of FHR and the average change in that rate seem to be the biggest factors for classifying fetal health.  We wanted to try and improve the Logistic regression by tuning the hyperparameters to improve both the recall and precision.  To attempt this we used a bagging classifer to train the logistic regression on multiple random samples and aggrigate the predictions to see how that effected the evaluation metrics.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:32.971910Z",
     "start_time": "2021-02-22T00:36:32.936552Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>Coefs</th>\n",
       "      <th>sm_Coefs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline value</td>\n",
       "      <td>0.117174</td>\n",
       "      <td>0.112113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accelerations</td>\n",
       "      <td>-0.004092</td>\n",
       "      <td>-0.224252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fetal_movement</td>\n",
       "      <td>0.010843</td>\n",
       "      <td>0.313262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uterine_contractions</td>\n",
       "      <td>-0.005320</td>\n",
       "      <td>-0.055485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>light_decelerations</td>\n",
       "      <td>-0.002220</td>\n",
       "      <td>-0.036389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>prolongued_decelerations</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>0.044586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abnormal_short_term_variability</td>\n",
       "      <td>0.069910</td>\n",
       "      <td>0.084350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mean_value_of_short_term_variability</td>\n",
       "      <td>-0.715013</td>\n",
       "      <td>-0.626913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>percentage_of_time_with_abnormal_long_term_var...</td>\n",
       "      <td>0.037261</td>\n",
       "      <td>0.039607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mean_value_of_long_term_variability</td>\n",
       "      <td>0.031932</td>\n",
       "      <td>0.045947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>histogram_width</td>\n",
       "      <td>-0.014467</td>\n",
       "      <td>-0.009616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>histogram_min</td>\n",
       "      <td>0.006391</td>\n",
       "      <td>-0.001040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>histogram_max</td>\n",
       "      <td>-0.008076</td>\n",
       "      <td>-0.010656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>histogram_number_of_peaks</td>\n",
       "      <td>0.251932</td>\n",
       "      <td>0.200837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>histogram_mode</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>-0.009779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>histogram_mean</td>\n",
       "      <td>0.031695</td>\n",
       "      <td>-0.059707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>histogram_median</td>\n",
       "      <td>-0.157476</td>\n",
       "      <td>-0.031339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>histogram_variance</td>\n",
       "      <td>0.032656</td>\n",
       "      <td>0.045463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>uterine_cont_per_min</td>\n",
       "      <td>-0.319218</td>\n",
       "      <td>-3.329097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>total_change</td>\n",
       "      <td>0.040625</td>\n",
       "      <td>0.062281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sqrt_total_change</td>\n",
       "      <td>-0.049447</td>\n",
       "      <td>-1.245735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>hist_zeros_1.0</td>\n",
       "      <td>0.064637</td>\n",
       "      <td>-0.514483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>hist_zeros_2.0</td>\n",
       "      <td>0.020156</td>\n",
       "      <td>-0.583633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>hist_zeros_3.0</td>\n",
       "      <td>-0.002722</td>\n",
       "      <td>-1.085404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>hist_zeros_4.0</td>\n",
       "      <td>0.017624</td>\n",
       "      <td>0.384853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>hist_zeros_5.0</td>\n",
       "      <td>-0.002252</td>\n",
       "      <td>-0.626686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>hist_zeros_7.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>hist_zeros_8.0</td>\n",
       "      <td>0.011021</td>\n",
       "      <td>0.195844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>hist_zeros_10.0</td>\n",
       "      <td>-0.000777</td>\n",
       "      <td>-0.629847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>hist_tendancy_0.0</td>\n",
       "      <td>-0.076557</td>\n",
       "      <td>-0.752577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>hist_tendancy_1.0</td>\n",
       "      <td>0.091930</td>\n",
       "      <td>-1.254315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>sev_decel_0.001</td>\n",
       "      <td>-0.003795</td>\n",
       "      <td>-0.238835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>quant_acc_1</td>\n",
       "      <td>-0.235999</td>\n",
       "      <td>-3.312252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>quant_light_dec_1</td>\n",
       "      <td>-0.344570</td>\n",
       "      <td>-1.669820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>quant_hist_mean_1</td>\n",
       "      <td>-0.467502</td>\n",
       "      <td>-2.735225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>quant_hist_mean_2</td>\n",
       "      <td>-0.255169</td>\n",
       "      <td>-2.348351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>quant_hist_mean_3</td>\n",
       "      <td>-0.356305</td>\n",
       "      <td>-2.624426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>quant_hist_mean_4</td>\n",
       "      <td>0.056211</td>\n",
       "      <td>-1.194180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>quant_hist_mean_5</td>\n",
       "      <td>0.428630</td>\n",
       "      <td>-0.125200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>quant_hist_mean_6</td>\n",
       "      <td>0.598199</td>\n",
       "      <td>0.816205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             features     Coefs  sm_Coefs\n",
       "0                                      baseline value  0.117174  0.112113\n",
       "1                                       accelerations -0.004092 -0.224252\n",
       "2                                      fetal_movement  0.010843  0.313262\n",
       "3                                uterine_contractions -0.005320 -0.055485\n",
       "4                                 light_decelerations -0.002220 -0.036389\n",
       "5                            prolongued_decelerations  0.000806  0.044586\n",
       "6                     abnormal_short_term_variability  0.069910  0.084350\n",
       "7                mean_value_of_short_term_variability -0.715013 -0.626913\n",
       "8   percentage_of_time_with_abnormal_long_term_var...  0.037261  0.039607\n",
       "9                 mean_value_of_long_term_variability  0.031932  0.045947\n",
       "10                                    histogram_width -0.014467 -0.009616\n",
       "11                                      histogram_min  0.006391 -0.001040\n",
       "12                                      histogram_max -0.008076 -0.010656\n",
       "13                          histogram_number_of_peaks  0.251932  0.200837\n",
       "14                                     histogram_mode -0.021053 -0.009779\n",
       "15                                     histogram_mean  0.031695 -0.059707\n",
       "16                                   histogram_median -0.157476 -0.031339\n",
       "17                                 histogram_variance  0.032656  0.045463\n",
       "18                               uterine_cont_per_min -0.319218 -3.329097\n",
       "19                                       total_change  0.040625  0.062281\n",
       "20                                  sqrt_total_change -0.049447 -1.245735\n",
       "21                                     hist_zeros_1.0  0.064637 -0.514483\n",
       "22                                     hist_zeros_2.0  0.020156 -0.583633\n",
       "23                                     hist_zeros_3.0 -0.002722 -1.085404\n",
       "24                                     hist_zeros_4.0  0.017624  0.384853\n",
       "25                                     hist_zeros_5.0 -0.002252 -0.626686\n",
       "26                                     hist_zeros_7.0  0.000000  0.000000\n",
       "27                                     hist_zeros_8.0  0.011021  0.195844\n",
       "28                                    hist_zeros_10.0 -0.000777 -0.629847\n",
       "29                                  hist_tendancy_0.0 -0.076557 -0.752577\n",
       "30                                  hist_tendancy_1.0  0.091930 -1.254315\n",
       "31                                    sev_decel_0.001 -0.003795 -0.238835\n",
       "32                                        quant_acc_1 -0.235999 -3.312252\n",
       "33                                  quant_light_dec_1 -0.344570 -1.669820\n",
       "34                                  quant_hist_mean_1 -0.467502 -2.735225\n",
       "35                                  quant_hist_mean_2 -0.255169 -2.348351\n",
       "36                                  quant_hist_mean_3 -0.356305 -2.624426\n",
       "37                                  quant_hist_mean_4  0.056211 -1.194180\n",
       "38                                  quant_hist_mean_5  0.428630 -0.125200\n",
       "39                                  quant_hist_mean_6  0.598199  0.816205"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a table of logistic regression coefficients and comparing the coefficients \n",
    "#of the SMOTE and inbalanced datasets\n",
    "coef_table = pd.DataFrame(list(X_train.columns)).copy()\n",
    "coef_table.insert(len(coef_table.columns),\"Coefs\",lr.coef_.transpose())\n",
    "\n",
    "coef_table_2 = pd.DataFrame(list(smX_train.columns)).copy()\n",
    "coef_table_2.insert(len(coef_table_2.columns),'sm_Coefs',smlr.coef_.transpose())\n",
    "\n",
    "smote_vs_coef = pd.concat([coef_table,coef_table_2],axis=1)\n",
    "smote_vs_coef.columns = ['features','Coefs','del','sm_Coefs']\n",
    "del smote_vs_coef['del']\n",
    "smote_vs_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:33.324810Z",
     "start_time": "2021-02-22T00:36:32.976115Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BaggingClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-be5fe5ff4bcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Bagging classifier for legistic regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m bag_log = BaggingClassifier(\n\u001b[0m\u001b[1;32m      3\u001b[0m     base_estimator=LogisticRegression(\n\u001b[1;32m      4\u001b[0m         random_state=1),n_estimators=200,\n\u001b[1;32m      5\u001b[0m     \u001b[0mmax_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.85\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BaggingClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "#Bagging classifier for legistic regression\n",
    "bag_log = BaggingClassifier(\n",
    "    base_estimator=LogisticRegression(\n",
    "        random_state=1),n_estimators=200,\n",
    "    max_samples=.85,\n",
    "    max_features=10,oob_score=True,\n",
    "    n_jobs=-1,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:33.331643Z",
     "start_time": "2021-02-22T00:36:28.258Z"
    }
   },
   "outputs": [],
   "source": [
    "#Fit bagging classifier\n",
    "bag_log.fit(smX_train, smy_train)\n",
    "y_pred = bag_log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:33.333872Z",
     "start_time": "2021-02-22T00:36:28.262Z"
    }
   },
   "outputs": [],
   "source": [
    "#Evaluation Metrics\n",
    "evaluation(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Bagging classifer made only minute changes to the evaluation metrics.  We decided to look at some other models and compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The next model we tried was a decision tree.  Again we compared the imbalanced and SMOTE data sets on baseline models to observe the effect on the metrics.  With the SMOTE data set, decision tree produced very good metrics with all default hyperparamers.  The most important features where abnormal_short_term_variability, and mean_value_of_short_term_variability\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:33.336157Z",
     "start_time": "2021-02-22T00:36:28.266Z"
    }
   },
   "outputs": [],
   "source": [
    "#Train decision tree with train set and predict on the test set\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "tree = tree.fit(X_train,y_train)\n",
    "\n",
    "y_pred = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:33.338516Z",
     "start_time": "2021-02-22T00:36:28.269Z"
    }
   },
   "outputs": [],
   "source": [
    "#Evaluation metrics\n",
    "evaluation(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:33.340638Z",
     "start_time": "2021-02-22T00:36:28.273Z"
    }
   },
   "outputs": [],
   "source": [
    "#Decision tree with smote dataset\n",
    "smtree = DecisionTreeClassifier()\n",
    "smtree.fit(smX_train,smy_train)\n",
    "y_pred = smtree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:33.342697Z",
     "start_time": "2021-02-22T00:36:28.276Z"
    }
   },
   "outputs": [],
   "source": [
    "#evaluation Metrics\n",
    "evaluation(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:33.345668Z",
     "start_time": "2021-02-22T00:36:28.281Z"
    }
   },
   "outputs": [],
   "source": [
    "#Table for decision tree feature coefficients\n",
    "coef_table = pd.DataFrame(list(X_train.columns)).copy()\n",
    "coef_table.insert(len(coef_table.columns),\"Coefs\",tree.feature_importances_.transpose())\n",
    "\n",
    "coef_table_2 = pd.DataFrame(list(smX_train.columns)).copy()\n",
    "coef_table_2.insert(len(coef_table_2.columns),'sm_Coefs',tree.feature_importances_.transpose())\n",
    "\n",
    "smote_vs_coef = pd.concat([coef_table,coef_table_2],axis=1)\n",
    "smote_vs_coef.columns = ['features','importance','del','sm_importance']\n",
    "del smote_vs_coef['del']\n",
    "smote_vs_coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we did above we used the SMOTE and imbalanced data and this time trained a random forest classifer.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:33.348541Z",
     "start_time": "2021-02-22T00:36:28.285Z"
    }
   },
   "outputs": [],
   "source": [
    "#Random Forest classifier using 50 estimators and a max depth of 3\n",
    "rfc = RandomForestClassifier(random_state =1, n_estimators= 50, max_depth = 3, n_jobs =-1,verbose=1)\n",
    "rfc.fit(X_train,y_train)\n",
    "y_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:33.350572Z",
     "start_time": "2021-02-22T00:36:28.288Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Evaluation metrics for random forest\n",
    "evaluation(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:33.352959Z",
     "start_time": "2021-02-22T00:36:28.292Z"
    }
   },
   "outputs": [],
   "source": [
    "#Random Forest classifier using 50 estimators and a max depth of 3 using SMOTE dataset\n",
    "smrfc = RandomForestClassifier(random_state =1, n_estimators= 50, max_depth = 3, n_jobs =-1,verbose=1)\n",
    "smrfc.fit(smX_train,smy_train)\n",
    "y_pred = smrfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:33.355625Z",
     "start_time": "2021-02-22T00:36:28.295Z"
    }
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "evaluation(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:33.358132Z",
     "start_time": "2021-02-22T00:36:28.299Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create table of feature coefficients\n",
    "coef_table = pd.DataFrame(list(X_train.columns)).copy()\n",
    "coef_table.insert(len(coef_table.columns),\"Coefs\",rfc.feature_importances_.transpose())\n",
    "\n",
    "coef_table_2 = pd.DataFrame(list(smX_train.columns)).copy()\n",
    "coef_table_2.insert(len(coef_table_2.columns),'sm_Coefs',smrfc.feature_importances_.transpose())\n",
    "\n",
    "smote_vs_coef = pd.concat([coef_table,coef_table_2],axis=1)\n",
    "smote_vs_coef.columns = ['features','importance_baseline','del','sm_importance_baseline']\n",
    "del smote_vs_coef['del']\n",
    "smote_vs_coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Random Forest\n",
    "- We ran a gridsearch on the random forest to identify what the best hyperparamters where for the model.  We checked several estimator sizes, max depth and min weight fraction leaf to find the ideal parameters.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:33.361244Z",
     "start_time": "2021-02-22T00:36:28.302Z"
    }
   },
   "outputs": [],
   "source": [
    "#parameter grid for grid search with lists of estimators, both criterion, a list of max depths sqrt max features \n",
    "#and a list of min weight fraction leaf\n",
    "parameters = {\n",
    "    'n_estimators': [25,50,100,300,500],\n",
    "    'criterion' : ['gini','entropy'],\n",
    "    'max_depth' : [8,9,10,11,12],\n",
    "    'max_features' : ['sqrt'],\n",
    "    'min_weight_fraction_leaf' : [0,0.1,0.3,0.5],\n",
    "    \n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:33.364876Z",
     "start_time": "2021-02-22T00:36:28.306Z"
    }
   },
   "outputs": [],
   "source": [
    "#Gridsearch with random forest\n",
    "grid_tree=GridSearchCV(RandomForestClassifier(), parameters, cv=15, scoring='f1', verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:33.367453Z",
     "start_time": "2021-02-22T00:36:28.309Z"
    }
   },
   "outputs": [],
   "source": [
    "#Fit random forest grid serch to SMOTE train set\n",
    "grid_tree.fit(smX_train, smy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:33.369662Z",
     "start_time": "2021-02-22T00:36:28.312Z"
    }
   },
   "outputs": [],
   "source": [
    "#Find the best score, best parameters and best estimator for grid search\n",
    "print(grid_tree.best_score_)\n",
    "print(grid_tree.best_params_)\n",
    "print(grid_tree.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:33.372394Z",
     "start_time": "2021-02-22T00:36:28.315Z"
    }
   },
   "outputs": [],
   "source": [
    "#evaluation metrics for random forest gridsearch best parameters\n",
    "y_pred = grid_tree.best_estimator_.predict(X_test)\n",
    "evaluation(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings:** \n",
    "- The best parameters for the random forest was a max depth of 11, min weight fraction leave of 0, and 500 estimators.  The Evaluation metrics where our highest score with the experimental set so far.  Below we compared feature importance for the three random forest models we ran and then graphed the top ten important features to visualize there importance for fetal health classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:33.375222Z",
     "start_time": "2021-02-22T00:36:28.320Z"
    }
   },
   "outputs": [],
   "source": [
    "#Best feature table for random forest gridsearch best parameters\n",
    "coef_table = pd.DataFrame(list(X_train.columns)).copy()\n",
    "coef_table.insert(len(coef_table.columns),\"Coefs\",grid_tree.best_estimator_.feature_importances_.transpose())\n",
    "coef_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:33.377805Z",
     "start_time": "2021-02-22T00:36:28.323Z"
    }
   },
   "outputs": [],
   "source": [
    "#table comparing random forest best features between imbalanced data set, smote and smote with gridsearch best features\n",
    "coef_table.columns = ['features','grid_search_importance']\n",
    "del coef_table['features']\n",
    "best_features_rfc = pd.concat([smote_vs_coef,coef_table],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:33.380231Z",
     "start_time": "2021-02-22T00:36:28.328Z"
    }
   },
   "outputs": [],
   "source": [
    "best_features_rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:33.382444Z",
     "start_time": "2021-02-22T00:36:28.331Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series(grid_tree.best_estimator_.feature_importances_, index=X.columns).nlargest(10).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**findings**\n",
    "- In the Above graphe you can see the top ten importanct features for our grid search random foret model.  Abnormal_short_term_variatability, acceleration and mean_value_of_short_term_varitability seem to be key factors in health classification.  We can infer from this that extended rapid extreme changes in fetal heart rate are detrimental to fetal health."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We wanted to try an XGboost classifer to attempt a better model than the gridsearch random forest.  XGboost uses gradiant descent and boosting principles to regression trees.  We first tried an XGboost model with some parametrs we thought would be ideal for the model.  Next we ran a grid search on the XGboost parameters to produce our best possible model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:33.385512Z",
     "start_time": "2021-02-22T00:36:28.334Z"
    }
   },
   "outputs": [],
   "source": [
    "xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:33.388078Z",
     "start_time": "2021-02-22T00:36:28.337Z"
    }
   },
   "outputs": [],
   "source": [
    "xg_clf = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                           colsample_bytree = 0.75, \n",
    "                           subsample = 0.85,\n",
    "                           learning_rate = 0.1,\n",
    "                           max_depth = 11, \n",
    "                           alpha = 1, \n",
    "                           n_estimators = 1000,\n",
    "                          verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:33.390317Z",
     "start_time": "2021-02-22T00:36:28.340Z"
    }
   },
   "outputs": [],
   "source": [
    "xg_clf.fit(smX_train,smy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:33.392864Z",
     "start_time": "2021-02-22T00:36:28.343Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = xg_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:33.395299Z",
     "start_time": "2021-02-22T00:36:28.345Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluation(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:33.397595Z",
     "start_time": "2021-02-22T00:36:28.348Z"
    }
   },
   "outputs": [],
   "source": [
    "coef_table = pd.DataFrame(list(X_train.columns)).copy()\n",
    "coef_table.insert(len(coef_table.columns),\"Coefs\",xg_clf.feature_importances_.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:33.400722Z",
     "start_time": "2021-02-22T00:36:28.352Z"
    }
   },
   "outputs": [],
   "source": [
    "coef_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:33.403961Z",
     "start_time": "2021-02-22T00:36:28.354Z"
    }
   },
   "outputs": [],
   "source": [
    "clf_xgb = xgb.XGBClassifier(objective = 'binary:logistic')\n",
    "param_dist = {'n_estimators': [500,1000,1500],\n",
    "              'learning_rate': [0.1,0.07,0.05,0.03,0.01],\n",
    "              'max_depth': [9,10,11,12,13],\n",
    "              'colsample_bytree': [0.5,0.45,0.4],\n",
    "              'min_child_weight': [1, 2, 3]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:33.407537Z",
     "start_time": "2021-02-22T00:36:28.357Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_xg = GridSearchCV(estimator=clf_xgb,\n",
    "                      param_grid= param_dist,\n",
    "                      scoring='f1',\n",
    "                      n_jobs=-1,\n",
    "                      verbose=1,\n",
    "                      iid=False,\n",
    "                      cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:33.411370Z",
     "start_time": "2021-02-22T00:36:28.360Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_xg.fit(smX_train,smy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:33.414616Z",
     "start_time": "2021-02-22T00:36:28.363Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_xg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:33.417318Z",
     "start_time": "2021-02-22T00:36:28.366Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = grid_xg.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:33.419458Z",
     "start_time": "2021-02-22T00:36:28.368Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluation(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:33.421319Z",
     "start_time": "2021-02-22T00:36:28.371Z"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "plot_importance(grid_xg.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T00:36:33.423789Z",
     "start_time": "2021-02-22T00:36:28.374Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_importance(grid_xg.best_estimator_,max_num_features=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**findings**\n",
    "- The grid search xgboost produced our overall best model.  We where extremely pleased with the highest recall and accuracy score.  The precision, which was our target metric was also very high.  When graphing the featrue importance, the most important features where abnormal_short_term_variatability and the histogram mean, min, width  and mode.  Our engineered features where not as important as some of the unchanged features.  Our best preforming engineered feature was sqrt_total_change, but no engineered feature was in the top ten.  Just like our random forest model short term varitability of the FHR is a key feature in classifying fetal health."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
